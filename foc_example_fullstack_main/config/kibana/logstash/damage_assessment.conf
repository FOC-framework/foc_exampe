input {
    jdbc {
        # Postgres jdbc connection string to our database, mydb
        jdbc_connection_string => "jdbc:postgresql://192.168.1.2:5432/fenix"
        # The user we wish to execute our statement as
        jdbc_user => "postgres"
        jdbc_password => ""
        # The path to our downloaded jdbc driver
        jdbc_driver_library => "/usr/share/logstash/logstash-core/lib/jars/postgresql-42.2.8.jar"
        # The name of the driver class for Postgresql
        jdbc_driver_class => "org.postgresql.Driver"
        jdbc_validate_connection => true
        schedule => "* * * * *"
        # our query
        statement => "SELECT * FROM damage_assessment_view WHERE damage_assessment_ref > ? AND damage_assessment_ref < ? + ? ORDER BY damage_assessment_ref ASC"
        prepared_statement_bind_values => [":sql_last_value", ":sql_last_value", 20000]
        prepared_statement_name => "damage_assessment"
        use_prepared_statements => true
        use_column_value => true
        tracking_column_type => "numeric"
        tracking_column => "damage_assessment_ref"
        last_run_metadata_path => "/etc/logstash/cursors/damage_assessment_last_value.yml"
    }
}

filter {
  mutate {convert => ["damage_assessment_geo_location_longitude", "float"]}
  mutate {convert => ["damage_assessment_geo_location_latitude", "float"]}
  mutate {
    rename => {"damage_assessment_geo_location_longitude" => "[damage_assessment_location][lon]"}
    rename => {"damage_assessment_geo_location_latitude" => "[damage_assessment_location][lat]"}
  }
}

output {
  elasticsearch {
    hosts => "localhost:9200"
    index => "damage_assessment_data"
    user => "elastic"
    password => "${ES_PWD}"
    document_id => "%{damage_assessment_ref}"
  }
}

